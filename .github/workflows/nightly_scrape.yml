name: Nightly Facebook Page Scrape

on:
  schedule:
    - cron: '*/5 * * * *' # Runs every night at 10 PM UTC
  workflow_dispatch: # Allows manual triggering

jobs:
  scrape_and_commit:
    runs-on: ubuntu-latest
    permissions:
      contents: write # Required to push commits

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9' # Specify Python version

      - name: Run scraper script
        run: |
          chmod +x run_scraper.sh
          ./run_scraper.sh
        shell: bash

      - name: Configure git
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"
        shell: bash

      - name: Commit and push changes
        run: |
          git pull # Ensure local repo is up-to-date before checking for changes
          git add facebook_pages.csv
          # Check if there are changes staged for commit
          if ! git diff --staged --quiet; then
            git commit -m "Update facebook_pages.csv with latest scrape"
            git push
          else
            echo "No changes to facebook_pages.csv to commit."
          fi
        shell: bash
